{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Principal Component Analysis (PCA) ----------\n",
    "\n",
    "# ----- Step 1: Standardisation -----\n",
    "\n",
    "# PCA is sensitive to variable variance, and so those those with larger ranges (e.g., between 0 and 100) will dominate over those with smaller ranges \n",
    "# (e.g., between 0 and 1). As such, standardisation is needed:\n",
    "\n",
    "#                                                       z = (value - mean) / standard deviation\n",
    "\n",
    "\n",
    "\n",
    "# ----- Step 2: Covariance Matrix Computation -----\n",
    "\n",
    "# A covariance matrix is a p x p (where p = no. of dimensions) symmetric matrix that contains the covariances associated with all possible input \n",
    "# variable pairs, where the main diagonal contains the variances of each input variable. Correlated variables have a positive covariance, while\n",
    "# inversely correlated variables have a negative covariance. A covariance matrix is thus nothing more than a table that summarises correlations \n",
    "# between all possible pairs.\n",
    "\n",
    "\n",
    "\n",
    "# ----- Step 3: Compute Eigenvectors and Eigenvalues -----\n",
    "\n",
    "# Eigenvectors (aka, the principal component; PC) indicate the direction in which the most variance occurs, while eigenvalues are coefficients that \n",
    "# quantify the amount of variance carried by each PC. Eigenvectors can be ranked in order of their eigenvalues, with the greatest eigenvalue\n",
    "# corresponding to the first PC (i.e., PC1). The percentage of variance associated with a given component can be calculated by dividing its eigenvalue\n",
    "# by the sum of eigenvalues.\n",
    "\n",
    "\n",
    "\n",
    "# ----- Step 4: Create a Feature Vector -----\n",
    "\n",
    "# A feature vector is a matrix containing the eigenvectors of features of interest. Components that carry a low percentage of overall variance may be\n",
    "# excluded at this step, which will reduce dimensionality/information equivalent to that percentage. \n",
    "\n",
    "\n",
    "\n",
    "# ----- Step 5: Recast the Data Along the PC Axis -----\n",
    "\n",
    "# In this step, we re-orient our data from the original axes to those represented by the PCs. This is done by multiplying the transpose of the \n",
    "# standardised dataset (SDS) acquired in step 1 by the transpose of the feature vector (FV) acquired in step 4:\n",
    "\n",
    "# dataset = FV ^ T * SDS ^ T\n",
    "\n",
    "\n",
    "\n",
    "# Source: https://builtin.com/data-science/step-step-explanation-principal-component-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual CDFS PCA matches sklearn PCA:  True\n",
      "Manual COS PCA matches sklearn PCA:  True\n",
      "Manual UDS PCA matches sklearn PCA:  True\n"
     ]
    }
   ],
   "source": [
    "# ----- Import Packages -----\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from init import data\n",
    "from numpy import cov\n",
    "import numpy as np\n",
    "\n",
    "from pkg import *\n",
    "\n",
    "\n",
    "\n",
    "# ----- Step 1: Standardisation -----\n",
    "\n",
    "def standardise(data):\n",
    "    for col in data.columns:\n",
    "        if col not in ['id', 'use', 'ir_agn', 'xray_agn', 'radio_agn', 'agn', 'true_agn']:\n",
    "            data[col] = (data[col] - data[col].mean()) / data[col].std()\n",
    "    return data\n",
    "\n",
    "#datasets = data()\n",
    "#cdfs, cos, uds = datasets['cdfs'], datasets['cos'], datasets['uds']\n",
    "\n",
    "# Separate the columns to exclude from PCA\n",
    "exclude_cols = ['id', 'use', 'ir_agn', 'xray_agn', 'radio_agn', 'agn', 'true_agn']\n",
    "\n",
    "# Standardize each dataset, excluding certain columns\n",
    "cdfs, cos, uds = cdfs.copy(), cos.copy(), uds.copy()\n",
    "\n",
    "cdfs = standardise(cdfs.drop(columns=exclude_cols))\n",
    "cos = standardise(cos.drop(columns=exclude_cols))\n",
    "uds = standardise(uds.drop(columns=exclude_cols))\n",
    "\n",
    "cdfs, cos, uds = standardise(cdfs), standardise(cos), standardise(uds)\n",
    "cdfs, cos, uds = np.array(cdfs), np.array(cos), np.array(uds)\n",
    "cdfs, cos, uds = np.nan_to_num(cdfs), np.nan_to_num(cos), np.nan_to_num(uds)\n",
    "\n",
    "\n",
    "\n",
    "# ----- Step 2: Covariance Matrix Computation -----\n",
    "\n",
    "pca_cdfs = PCA()\n",
    "pca_cos = PCA()\n",
    "pca_uds = PCA()\n",
    "\n",
    "cdfs_sklearn = pca_cdfs.fit_transform(cdfs)\n",
    "cos_sklearn = pca_cos.fit_transform(cos)\n",
    "uds_sklearn = pca_uds.fit_transform(uds)\n",
    "\n",
    "cov_matrix_cdfs, cov_matrix_cos, cov_matrix_uds = np.cov(cdfs, rowvar = False), np.cov(cos, rowvar = False), np.cov(uds, rowvar = False)\n",
    "\n",
    "\n",
    "\n",
    "# ----- Step 3: Compute Eigenvectors and Eigenvalues -----\n",
    "\n",
    "# Eigenvectors and eigenvalues are computed using NumPy's eig() function, which returns a tuple containing the eigenvectors and eigenvalues. The\n",
    "# eigenvectors are stored in the columns of the matrix, and the eigenvalues are stored in a one-dimensional array.\n",
    "\n",
    "eig_vals_cdfs, eig_vecs_cdfs = np.linalg.eig(cov_matrix_cdfs); eig_vals_cos, eig_vecs_cos = np.linalg.eig(cov_matrix_cos); eig_vals_uds, eig_vecs_uds = np.linalg.eig(cov_matrix_uds)\n",
    "\n",
    "eig_pairs_cdfs, eig_pairs_cos, eig_pairs_uds = [(eig_vals_cdfs[i], eig_vecs_cdfs[:, i]) for i in range(len(eig_vals_cdfs))], [(eig_vals_cos[i], eig_vecs_cos[:, i]) for i in range(len(eig_vals_cos))], [(eig_vals_uds[i], eig_vecs_uds[:, i]) for i in range(len(eig_vals_uds))]\n",
    "\n",
    "eig_pairs_cdfs.sort(key = lambda x: x[0], reverse = True); eig_pairs_cos.sort(key = lambda x: x[0], reverse = True); eig_pairs_uds.sort(key = lambda x: x[0], reverse = True)\n",
    "\n",
    "sorted_eig_vecs_cdfs, sorted_eig_vecs_cos, sorted_eig_vecs_uds = np.array([eig_pairs_cdfs[i][1] for i in range(len(eig_vals_cdfs))]).T, np.array([eig_pairs_cos[i][1] for i in range(len(eig_vals_cos))]).T, np.array([eig_pairs_uds[i][1] for i in range(len(eig_vals_uds))]).T\n",
    "\n",
    "# Align Signs\n",
    "\n",
    "for i in range(len(eig_vecs_cdfs)):\n",
    "    if np.dot(sorted_eig_vecs_cdfs[:, i], pca_cdfs.components_[i]) < 0:\n",
    "        sorted_eig_vecs_cdfs[:, i] = -sorted_eig_vecs_cdfs[:, i]\n",
    "\n",
    "for i in range(len(eig_vecs_cos)):\n",
    "    if np.dot(sorted_eig_vecs_cos[:, i], pca_cos.components_[i]) < 0:\n",
    "        sorted_eig_vecs_cos[:, i] = -sorted_eig_vecs_cos[:, i]\n",
    "\n",
    "for i in range(len(eig_vecs_uds)):\n",
    "    if np.dot(sorted_eig_vecs_uds[:, i], pca_uds.components_[i]) < 0:\n",
    "        sorted_eig_vecs_uds[:, i] = -sorted_eig_vecs_uds[:, i]\n",
    "\n",
    "\n",
    "\n",
    "# ----- Step 4: Create a Feature Vector -----\n",
    "        \n",
    "# The feature vector is created by sorting the eigenvectors based on their corresponding eigenvalues in descending order. The eigenvectors with the\n",
    "# largest eigenvalues contain the most information about the data. The feature vector is a matrix where each column represents an eigenvector.\n",
    "\n",
    "# Center Data\n",
    "        \n",
    "mean_cdfs, mean_cos, mean_uds = np.mean(cdfs, axis = 0), np.mean(cos, axis = 0), np.mean(uds, axis = 0)\n",
    "centered_cdfs, centered_cos, centered_uds = cdfs - mean_cdfs, cos - mean_cos, uds - mean_uds\n",
    "\n",
    "# Project Data\n",
    "\n",
    "cdfs_manual, cos_manual, uds_manual = np.dot(centered_cdfs, sorted_eig_vecs_cdfs), np.dot(centered_cos, sorted_eig_vecs_cos), np.dot(centered_uds, sorted_eig_vecs_uds)\n",
    "\n",
    "# Remove Imaginary Component\n",
    "                                                                                                                                     \n",
    "cdfs_manual, cos_manual, uds_manual = np.real(cdfs_manual), np.real(cos_manual), np.real(uds_manual)\n",
    "\n",
    "# Print and Compare Results\n",
    "\n",
    "np.savetxt('cdfs_manual.txt', cdfs_manual, delimiter = ',', fmt = '%.11f')\n",
    "np.savetxt('cdfs_auto.txt', cdfs_sklearn, delimiter = ',', fmt = '%.11f')\n",
    "\n",
    "print(\"Manual CDFS PCA matches sklearn PCA: \", np.allclose(cdfs_manual, cdfs_sklearn))\n",
    "print(\"Manual COS PCA matches sklearn PCA: \", np.allclose(cos_manual, cos_sklearn))\n",
    "print(\"Manual UDS PCA matches sklearn PCA: \", np.allclose(uds_manual, uds_sklearn))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
